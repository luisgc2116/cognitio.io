<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>Intellectus EX-Machina</title>
	<meta name="viewpoint" content="width=device-width, initial-scale=1">
	<!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  	<script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  	</script> -->
	<link rel="blog1" 
		href="https://use.fontawesome.com/releases/v5.7.1/css/all.css"
	  	integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr"
	  	crossorigin="anonymous">
	
    <link rel="stylesheet" type="text/css" href="../../../../css/posts.css">
	<meta charset="utf-8">
	
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
	<link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
	<!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
	<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML"></script>
	<link rel="canonical" href="https://luisgc2116.github.io/luis_notes/">

	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>


<body>
    <!--- Header and nav template site-wide -->
	<header>
	    <nav class="group">
	    <a href="/luis_notes/" class="header_items">Contents</a>
	    <a href="https://github.com/luisgc2116/" class="header_items">GitHub</a>
	    </nav>
	</header>

	<section>
		<h2 class="article_headers">Fundamentals of Probability: Introduction to Probability</h2>
		
		<h3 class="article_headers">I. Introduction:</h3>
		<div class='format_block'>
			<div class='format_block_left'>
				<p class="left_block_text">
					Main Idea:
				</p>
				<div class="left_block_text_indent_1">
					<p class='left_indented_p1'>
						Probability can be described, at a very high level, as the <i>ratio of an element over the total number of elements</i>. We will expand on a mathematically-consistent definition in another article on probability spaces, but for now, we can simply think of probabilities are these ratios.

						\begin{equation}
							p(\text{element}) = \frac{\text{element}}{\text{all_elements}}
						\end{equation}
						<br><br>
					</p>
					<div class="left_block_text_indent_2">
						<p class='left_indented_p2'>
								<i>Largely, the expectations or distributions we are trying to estimate are intractible, and so approximation is usually the best method toward inference. </i> 
								<br><br>
						</p>
					</div>
				</div>
				<button class="collapsible">More on Background and History:</button>
				<div class="content">
				 	<p class="collapsible_text">
				 		The usual example for probabilities is to reference a dice; here, the probability of each side would be 1/6, because there are 6 total elements, and each element appears once. What if we have two faces that have the same side? Well the value of that side would have a probability of 2/6.
				 		<br><br><br>
				 	</p>
				</div>	
			</div>
			<div class='format_block_right'>
				<p class="right_block_titles">Note: <br> </p>
				<p class="right_block_descriptions">
					A better way to describe an element is as an <i>event</i>>. We will see a more defined mathematical framework for this, but for now, we can just name them 
				</p>
			</div> 
		</div>

		<h3 class="article_headers">II. Theory Pt.1:</h3>
		<div class='format_block'>
			<!-- LEFT BLOCK -->
			<div class='format_block_left'>
				<p>
					Initial Definition: 
				</p>
				<div class="left_block_text_indent_1">
					<p class='left_indented_p1'>
						Since we can think of probabilities as just taking fraction of elements with respect to the total amount of elements, the sum of all of these elements is 1. You can think of it as taking slices of a pie; no matter how many pieces to make from it, the addition of these pieces divided by the total pie will equal 1. 
					</p>

					<p class="equation_left_indent_1">
							\begin{align} 
								\sum_{i=1}^\infty P(\text{elem_i}) = \sum_{i=1}^\infty \frac{\text{elem}_i}{\text{all_elements}}
							\end{align}<br>
					</p>
				</div>

				<p>A Few Remarks:</p>
				<div class="left_block_text_indent_0">
					<p class='left_indented_p1'>
						Mathematically, the sum of probabilities can be expressed as,
					</p>
				</div>
				<div class='format_block_left'>
					<ul class="left_block_list_normal">
						<li>
							The sum of individual ratios with respect to the total sum of elements,

							\begin{align}
							    \sum_{i=1}^\infty P(\text{elem_i})
							        &= \sum_{i=1}^\infty \frac{\text{elem}_i}{\text{all_elements}} \\
							        &= \frac{1}{\text{all_elements}} \sum_{i=1}^\infty \text{elem}_i \\
							        &= \frac{\text{all_elements}}{\text{all_elements}} \\
							        &= 1
							\end{align}
						</li>
						<li>
							The sum of all elements over the total elements, both of which equal one,

							\begin{align}
							    \sum_{i=1}^\infty P(\text{elem_i})
							        &= \sum_{i=1}^\infty \frac{\text{elem}_i}{\text{all_elements}} \\
							        &= \frac{\text{elem}_1}{\text{all_elements}} + \dots + \frac{\text{elem}_k}{\text{all_elements}} \\
							        &= \frac{\text{elem}_1 + \dots + \text{elem}_k}{\text{all_elements}} \\
							        &= \frac{\text{all_elements}}{\text{all_elements}} \\
							        &= 1
							\end{align}

							<br><br>
						</li>
					</ul>

					<!-- <button class="collapsible">Example 1: Area of an Object</button>
					<div class="content">
					 	<p class="collapsible_text">
					 		Let's say we have a circle circumscibed onto a square. Here the area of the circle is \( A(\text{circle})=\pi r^2 \) and the area of the square is \( A(\text{square})= 4r^2 \). The ratio of the area of the circle to the area of the square is then 
					 		\( \frac{A(\text{circle})}{A(\text{square})}= \frac{\pi r^2}{4 r^2} = \frac{\pi}{4} \). <br><br>

					 		Let's approximate this ratio by asking: <i>if we randomly threw points in the area of the square, what is the ratio of points that land in the circle to the total number of thrown points</i>. 

					 		\begin{align}
					 			\frac{A(\text{circle})}{A(\text{square})} 
					 				&= \mathbb{E} \bigg[ \frac{\text{num_points_inside_circle}}{\text{tot_num_points}} \bigg] \\
					 				&\approx \sum_i^N \bigg( \frac{\text{num_points_inside_circle}}{\text{tot_num_points}} \bigg) \\
					 				&\approx \frac{1}{N} \sum_i^N \bigg( text{num_points_inside_circle} \bigg) \\
					 				&\approx \frac{1}{N} \sum_i^N (x_i^2 + y_i^2 \leq r^2) \\
					 				&= \text{sample_ratio}
					 		\end{align}

					 		Typically, this example is used to approximate \( \pi \), because as this sample ratio gets better, we have that it equals \( \frac{\pi}{4} \). Therefore, we can just approximate \( \pi \) as \( \pi = 4 \cdot \text{sample_ratio} \) .
					 		<br><br>
					 	</p>
					</div> -->	
				</div>	
			</div>

 

			<!-- RIGHT BLOCK -->
			<div class='format_block_right'>

				<p class="right_block_titles"> Note: <br> </p>
				<p class="right_block_descriptions">
					Another interesting fact about the variance converging at a rate of \( \frac{1}{n} \) is that this rate is <b>independent</b> of the number of dimensions in x. This is due to the sampling f(x) assuming a one dimensional quantity.
				</p>

				
			</div>
		</div>

		<h3 class="article_headers">III. Theory Pt.2:</h3>
		<div class='format_block'>
			<!-- LEFT BLOCK -->
			<div class='format_block_left'>
				<p>
					Distributions: 
				</p>
				<div class="left_block_text_indent_1">
					<p class='left_indented_p1'>
						The sum of all probabilities must equal 1, but there's no real other restriction on how the values of these probabilities should be distributed. You can have probabilities that are all equal, or ones with high probabilities for some elements and low for others. 

						We call the distribution of probabilities for a set of elements simply a *distribution*. As long as sum of all probabilities in this distribution sums to 1, the distribution is valid. 
					</p>

					<p class="equation_left_indent_1">
							\begin{align} 
								\sum_{i=1}^\infty P(\text{elem_i}) = \sum_{i=1}^\infty \frac{\text{elem}_i}{\text{all_elements}}
							\end{align}<br>
					</p>
				</div>

				<p>
					Random Variables: 
				</p>
				<div class="left_block_text_indent_1">
					<p class='left_indented_p1'>
						We can think of a random variable as a function that takes as input an element, and outputs the probability of that element. The probabilities assigned to each element is dependent on what probability distribution we choose, and so mathematically, you see a random variable defined as 
						<br><br>
					</p>

					<p class="equation_left_indent_1">
							\begin{align}
							    X \sim \text{Distribution}
							\end{align}<br>
					</p>

					<p class='left_indented_p1'>
						Notation: Upper case letters are random variables, and lower case letters are the values within the distribution. So \( p(X=x_i) \) is the probability of \( x_i \). It's often the case that probabilities are simply written as \( p(x_i) \).
						<br><br>
					</p>

				</div>

				<p>
					Sampling: 
				</p>
				<div class="left_block_text_indent_1">
					<p class='left_indented_p1'>
						What can we do with this random variable? Well, we take a random value from this *random variable* by picking a value in accordance to the probability distribution it is being described by. Therefore, each time you get a value, it may NOT be the same value; it is not deterministic.

						Getting a random value from a random variable described by a distribution is known as *sampling*.

						Often, sampling is introduced as imagining having a bag of marbles of colors blue and red. If you grab a marble randomly from the bag, this action is sampling.
						<br><br>
					</p>
				</div>

				<p>
					Expectation: 
				</p>
				<div class="left_block_text_indent_1">
					<p class='left_indented_p1'>
						Since we now have an undeterministic system that maps elements to their respective probabilities, we can ask what the average of those elements are. 
						Mathematically, we can be more specific by asking: what is the average value of those elements is with respect to their probabilities? 

						We can therefore start with the definition of a weighted average, which is described as: the sum of values with weights normalized by the sum of the weights.
					</p>
					<p class="equation_left_indent_1">
							\begin{align}
							    \overline{X} = \frac{\sum w \, x}{\sum w}
							\end{align}
							<br><br>
					</p>
					<p class='left_indented_p1'>
						This equation might seem confusing at first but another way to look at it is to each value being applied to a normalized weight. These normalized weights are the ratios of its weight to the total sum of the weights.
					</p>
					<p class="equation_left_indent_1">
							\begin{align}
							    \overline{X} 
							        &= \frac{\sum_i w_i \, x_i}{\sum w_j} \\
							        &= \sum_i x_i \, \bigg( \frac{w_i}{\sum_j w_j} \bigg) \\
							\end{align}
							<br><br>
					</p>
					<p class='left_indented_p1'>
						This may sound familiar. Recall that probabilities can be though of as the ratio of an element to the total elements. If we write the weights as elements, normalized weights are then the probabilities of a respective element. Therefore, we can write the same weighted average equation as the sum of elements with probabilities normalized by the sum of all  their respective probabilities.
					</p>
					<p class="equation_left_indent_1">
							\begin{align}
							    \overline{X} 
							        &= \sum_i x_i \, \bigg( \frac{w_i}{\sum_j w_j} \bigg) \\
							        &= \sum_i x_i \, \bigg( \frac{\text{elem}_i}{\sum_j \text{elem}_j} \bigg) \\
							        &= \sum_i x_i \, \bigg( \frac{x_i}{\sum_j x_j} \bigg) \\
							        &= \sum_i x_i \, p(x_i)
							\end{align}
							<br><br>
					</p>
					<p class='left_indented_p1'>
						Being more explicit, the weighted average the element values of X and their respective probabilities is given the name of <i>Expected Value</i>, \( \mathbb{E}[X] \).
					</p>
					<p class="equation_left_indent_1">
						\begin{align}
						    \mathbb{E}[X] 
						        &= \sum_{i=1}^n x_{i} \, p(x_i)
						\end{align}
						<br><br>
					</p>
					<p class='left_indented_p1'>
						Expanding on the Expected Value a little more, we can say that it is with respect to any probability distribution p.
					</p>
					<p class="equation_left_indent_1">
						\begin{align}
						    \mathbb{E}_{X \sim p(x)}[g(X)] 
						        &= \sum_{i=1}^n g(x_{i}) \, p(x_i)
						\end{align}
						<br><br>
					</p>
					<p class='left_indented_p1'>
						Furthermore, we can take the expectation of a function of a random variable, $g(X)$ with respect to a distribution of X, $X \sim p(x)$, 
					</p>
					<p class="equation_left_indent_1">
						\begin{align}
						    \mathbb{E}_{X \sim p(x)}[g(X)] 
						        &= \sum_{i=1}^n g(x_{i}) \, p(x_i)
						\end{align}
						<br><br>
					</p>
				</div>

				<p>Moments:</p>
				<div class="left_block_text_indent_1">
					<p class='left_indented_p1'>
						A quick introduction to moments is that they are defined as 
					</p>
					<p class="equation_left_indent_1">
						\begin{align}
						    \mathbb{E}_{X \sim p(x)}[X^n] 
						        &= \sum_{i=1}^n x_{i}^n \, p(x_i)
						\end{align} 
					</p>
				</div>

				<p>Variance:</p>
				<div class="left_block_text_indent_1">
					<p class='left_indented_p1'>
						If we wanted to know the average distance away from the expected value, we can find the square distance,
					</p>
					<p class="equation_left_indent_1">
						\begin{align}
						    \text{Var}[X]
						        &= \mathbb{E}[(X-\mathbb{E}[X])^2] \\
						        &= \mathbb{E}[X^2 - 2X\mathbb{E}[X] + \mathbb{E}[X]^2]  \\
						        &= \mathbb{E}[X^2] - 2\mathbb{E}[X]\mathbb{E}[X] + \mathbb{E}[X]^2  \\
						        &= \mathbb{E}[X^2] - 2\mathbb{E}[X]^2 + \mathbb{E}[X]^2  \\
						        &= \mathbb{E}[X^2] -  \mathbb{E}[X]^2
						         \\
						\end{align}  
					</p>
				</div>
			</div>

 

			<!-- RIGHT BLOCK -->
			<div class='format_block_right'>

				<p class="right_block_titles"> Note: <br> </p>
				<p class="right_block_descriptions">
					Note: Weighted averages are \( \min(X) \leq \overline{X} \leq \max(X) \).
				</p>

				
			</div>
		</div>

		<div class="left_block_space">
			
		</div>

	</section>

	<script>
		var coll = document.getElementsByClassName("collapsible");
		var i;
		for (i = 0; i < coll.length; i++) {
		  coll[i].addEventListener("click", function() {
		    this.classList.toggle("active");
		    var content = this.nextElementSibling;
		    if (content.style.maxHeight){
		      content.style.maxHeight = null;
		    } else {
		      content.style.maxHeight = content.scrollHeight + "px";
		    } 
		  });
		}

		var coll = document.getElementsByClassName("collapsible_right");
		var i;
		for (i = 0; i < coll.length; i++) {
		  coll[i].addEventListener("click", function() {
		    this.classList.toggle("active");
		    var content = this.nextElementSibling;
		    if (content.style.maxHeight){
		      content.style.maxHeight = null;
		    } else {
		      content.style.maxHeight = content.scrollHeight + "px";
		    } 
		  });
		}
	</script>
</body>

<!-- <footer>
	<hr class="footer_line">
	<h3>Sources</h3>
</footer> -->
</html>